name: k8s load testing ci

on:
  pull_request:
    branches:
      - master

permissions:
  contents: read
  pull-requests: write
  issues: write

jobs:
  load-test:
    runs-on: ubuntu-latest  # uses largest available runner for your account

    steps:
      - name: checkout code
        uses: actions/checkout@v4

      - name: install kind
        run: |
          # installing kind for local k8s cluster
          curl -Lo ./kind https://kind.sigs.k8s.io/dl/v0.20.0/kind-linux-amd64
          chmod +x ./kind
          sudo mv ./kind /usr/local/bin/kind

      - name: install kubectl
        run: |
          # getting kubectl to interact with the cluster
          curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
          chmod +x kubectl
          sudo mv kubectl /usr/local/bin/

      - name: install k6
        run: |
          # installing k6 for load testing
          sudo gpg -k
          sudo gpg --no-default-keyring --keyring /usr/share/keyrings/k6-archive-keyring.gpg --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys C5AD17C747E3415A3642D57D77C6C491D6AC1D69
          echo "deb [signed-by=/usr/share/keyrings/k6-archive-keyring.gpg] https://dl.k6.io/deb stable main" | sudo tee /etc/apt/sources.list.d/k6.list
          sudo apt-get update
          sudo apt-get install k6

      - name: create kind cluster
        run: |
          echo "creating multi-node kind cluster..."
          kind create cluster --config k8s/kind-config.yaml --wait 5m

          # waiting for nodes to be ready
          kubectl wait --for=condition=Ready nodes --all --timeout=300s

          echo "cluster nodes:"
          kubectl get nodes

      - name: deploy nginx ingress
        run: |
          echo "deploying nginx ingress controller..."
          # using official nginx ingress for kind
          kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/main/deploy/static/provider/kind/deploy.yaml

          # waiting for ingress controller deployment to be ready (not admission jobs)
          echo "waiting for ingress controller deployment..."
          kubectl wait --namespace ingress-nginx \
            --for=condition=ready pod \
            --selector=app.kubernetes.io/component=controller \
            --timeout=300s

          echo "ingress controller status:"
          kubectl get pods -n ingress-nginx

      - name: deploy applications
        run: |
          echo "deploying foo and bar apps..."
          kubectl apply -f k8s/apps/foo-deployment.yaml
          kubectl apply -f k8s/apps/bar-deployment.yaml
          kubectl apply -f k8s/apps/ingress-routes.yaml

          # waiting for deployments to be ready
          kubectl wait --for=condition=available --timeout=300s \
            deployment/foo-app deployment/bar-app

          echo "application status:"
          kubectl get pods
          kubectl get ingress

      - name: deploy prometheus
        run: |
          echo "deploying prometheus for monitoring..."
          kubectl apply -f k8s/monitoring/prometheus.yaml

          # waiting for prometheus to be ready
          kubectl wait --namespace monitoring \
            --for=condition=available --timeout=300s \
            deployment/prometheus

          echo "prometheus status:"
          kubectl get pods -n monitoring

      - name: validate cluster health
        run: |
          echo "validating cluster health..."

          # checking if deployments are ready
          kubectl get deployments
          kubectl get ingress

          # check ingress controller service
          echo "checking ingress controller service..."
          kubectl get svc -n ingress-nginx

          # check if port 80 is listening
          echo "checking if port 80 is accessible..."
          netstat -tuln | grep :80 || echo "port 80 not listening yet"

          # check docker port mappings
          docker ps | grep kind-control-plane

          # give ingress a bit more time to fully configure routes
          echo "waiting for ingress to fully initialize..."
          sleep 20

          # testing foo endpoint with better retry logic
          echo "testing foo.localhost..."
          SUCCESS=false
          for i in {1..15}; do
            RESPONSE=$(curl -s -w "\n%{http_code}" -H "Host: foo.localhost" http://localhost/ 2>&1 || echo "000")

            if echo "$RESPONSE" | tail -1 | grep -q "200"; then
              BODY=$(echo "$RESPONSE" | head -n -1)
              if echo "$BODY" | grep -q "foo"; then
                echo "✓ foo endpoint working"
                SUCCESS=true
                break
              fi
            fi

            echo "attempt $i failed, retrying in 3s..."
            sleep 3
          done

          if [ "$SUCCESS" = false ]; then
            echo "direct access failed, trying via ingress controller pod..."

            # get ingress controller pod name
            INGRESS_POD=$(kubectl get pods -n ingress-nginx -l app.kubernetes.io/component=controller -o jsonpath='{.items[0].metadata.name}')

            # test via ingress controller
            RESPONSE=$(kubectl exec -n ingress-nginx $INGRESS_POD -- curl -s -H "Host: foo.localhost" http://foo-service.default.svc.cluster.local/)

            if echo "$RESPONSE" | grep -q "foo"; then
              echo "✓ foo endpoint working via ingress controller"
              SUCCESS=true
            else
              echo "foo endpoint validation failed"
              kubectl describe ingress foo-ingress
              kubectl get pods -o wide
              kubectl logs -n ingress-nginx $INGRESS_POD --tail=50
              exit 1
            fi
          fi

          # testing bar endpoint
          echo "testing bar.localhost..."
          SUCCESS=false
          for i in {1..15}; do
            RESPONSE=$(curl -s -w "\n%{http_code}" -H "Host: bar.localhost" http://localhost/ 2>&1 || echo "000")

            if echo "$RESPONSE" | tail -1 | grep -q "200"; then
              BODY=$(echo "$RESPONSE" | head -n -1)
              if echo "$BODY" | grep -q "bar"; then
                echo "✓ bar endpoint working"
                SUCCESS=true
                break
              fi
            fi

            echo "attempt $i failed, retrying in 3s..."
            sleep 3
          done

          if [ "$SUCCESS" = false ]; then
            echo "direct access failed, trying via ingress controller pod..."

            # get ingress controller pod name
            INGRESS_POD=$(kubectl get pods -n ingress-nginx -l app.kubernetes.io/component=controller -o jsonpath='{.items[0].metadata.name}')

            # test via ingress controller
            RESPONSE=$(kubectl exec -n ingress-nginx $INGRESS_POD -- curl -s -H "Host: bar.localhost" http://bar-service.default.svc.cluster.local/)

            if echo "$RESPONSE" | grep -q "bar"; then
              echo "✓ bar endpoint working via ingress controller"
              SUCCESS=true
            else
              echo "bar endpoint validation failed"
              kubectl describe ingress bar-ingress
              kubectl get pods -o wide
              kubectl logs -n ingress-nginx $INGRESS_POD --tail=50
              exit 1
            fi
          fi

          echo "✓ all health checks passed"

      - name: setup port forwarding for load test
        run: |
          echo "setting up port forward to ingress controller..."

          # port forward ingress controller to localhost:8080 (port 80 requires root)
          kubectl port-forward -n ingress-nginx svc/ingress-nginx-controller 8080:80 &
          PF_PID=$!
          echo $PF_PID > /tmp/ingress-pf.pid

          # wait for port forward to be ready
          sleep 5

          # verify port forward is working
          SUCCESS=false
          for i in {1..15}; do
            if curl -s -H "Host: foo.localhost" http://localhost:8080/ | grep -q "foo"; then
              echo "✓ port forward working on localhost:8080"
              SUCCESS=true
              break
            fi
            echo "waiting for port forward... ($i/15)"
            sleep 2
          done

          if [ "$SUCCESS" = false ]; then
            echo "❌ port forward failed to start"
            # check if process is still running
            if ps -p $PF_PID > /dev/null; then
              echo "port-forward process is running but not responding"
            else
              echo "port-forward process died"
            fi
            exit 1
          fi

      - name: run load tests
        id: load-test
        run: |
          echo "running k6 load tests..."

          # capturing k6 output
          k6 run scripts/load-test.js > load-test-output.txt 2>&1 || true

          # showing results
          cat load-test-output.txt

      - name: stop port forwarding
        if: always()
        run: |
          if [ -f /tmp/ingress-pf.pid ]; then
            kill $(cat /tmp/ingress-pf.pid) || true
          fi

      - name: collect prometheus metrics
        run: |
          echo "collecting resource utilization from prometheus..."

          # port forward to prometheus in background
          kubectl port-forward -n monitoring svc/prometheus 9090:9090 &
          PF_PID=$!
          sleep 5

          # query prometheus for cpu and memory metrics during load test
          # getting average cpu usage for foo and bar pods
          FOO_CPU=$(curl -s 'http://localhost:9090/api/v1/query?query=avg(rate(container_cpu_usage_seconds_total{pod=~"foo-app.*"}[2m]))' | jq -r '.data.result[0].value[1] // "0"')
          BAR_CPU=$(curl -s 'http://localhost:9090/api/v1/query?query=avg(rate(container_cpu_usage_seconds_total{pod=~"bar-app.*"}[2m]))' | jq -r '.data.result[0].value[1] // "0"')

          # getting average memory usage
          FOO_MEM=$(curl -s 'http://localhost:9090/api/v1/query?query=avg(container_memory_usage_bytes{pod=~"foo-app.*"})' | jq -r '.data.result[0].value[1] // "0"')
          BAR_MEM=$(curl -s 'http://localhost:9090/api/v1/query?query=avg(container_memory_usage_bytes{pod=~"bar-app.*"})' | jq -r '.data.result[0].value[1] // "0"')

          # set defaults if empty
          FOO_CPU=${FOO_CPU:-0}
          BAR_CPU=${BAR_CPU:-0}
          FOO_MEM=${FOO_MEM:-0}
          BAR_MEM=${BAR_MEM:-0}

          # convert memory to MB (handle empty values)
          if [ "$FOO_MEM" != "0" ]; then
            FOO_MEM_MB=$(echo "scale=2; $FOO_MEM / 1024 / 1024" | bc)
          else
            FOO_MEM_MB="0"
          fi

          if [ "$BAR_MEM" != "0" ]; then
            BAR_MEM_MB=$(echo "scale=2; $BAR_MEM / 1024 / 1024" | bc)
          else
            BAR_MEM_MB="0"
          fi

          # convert cpu to percentage (handle empty values)
          if [ "$FOO_CPU" != "0" ]; then
            FOO_CPU_PCT=$(echo "scale=2; $FOO_CPU * 100" | bc)
          else
            FOO_CPU_PCT="0"
          fi

          if [ "$BAR_CPU" != "0" ]; then
            BAR_CPU_PCT=$(echo "scale=2; $BAR_CPU * 100" | bc)
          else
            BAR_CPU_PCT="0"
          fi

          # save metrics to file
          cat > prometheus-metrics.txt << EOF
          FOO_CPU=$FOO_CPU_PCT
          BAR_CPU=$BAR_CPU_PCT
          FOO_MEM=$FOO_MEM_MB
          BAR_MEM=$BAR_MEM_MB
          EOF

          cat prometheus-metrics.txt

          # kill port-forward
          kill $PF_PID || true

      - name: parse load test results
        id: parse-results
        run: |
          # parsing the k6 output to extract key metrics for pr comment

          cat > parse-results.sh << 'EOF'
          #!/bin/bash

          # extracting metrics from k6 output
          OUTPUT=$(cat load-test-output.txt)

          # getting http request stats
          AVG_DURATION=$(echo "$OUTPUT" | grep "http_req_duration" | grep "avg=" | sed 's/.*avg=\([0-9.]*\).*/\1/' | head -1)
          P90_DURATION=$(echo "$OUTPUT" | grep "http_req_duration" | grep "p(90)=" | sed 's/.*p(90)=\([0-9.]*\).*/\1/' | head -1)
          P95_DURATION=$(echo "$OUTPUT" | grep "http_req_duration" | grep "p(95)=" | sed 's/.*p(95)=\([0-9.]*\).*/\1/' | head -1)

          # getting request rate
          REQ_RATE=$(echo "$OUTPUT" | grep "http_reqs" | grep -oP '\d+\.\d+/s' | head -1)

          # getting error rate
          ERROR_RATE=$(echo "$OUTPUT" | grep "✗" | grep "errors" | awk '{print $NF}' | head -1 || echo "0%")

          # getting total requests
          TOTAL_REQS=$(echo "$OUTPUT" | grep "http_reqs" | awk '{print $2}' | head -1)

          # getting vus
          VUS=$(echo "$OUTPUT" | grep "vus " | awk '{print $3}' | head -1)

          # loading prometheus metrics
          source prometheus-metrics.txt 2>/dev/null || true

          # creating markdown summary
          cat > comment.md << COMMENT
          ## load test results

          ### test configuration
          - virtual users: ${VUS:-50}
          - duration: 2 minutes
          - targets: foo.localhost, bar.localhost (randomized)

          ### results

          **http request metrics:**
          - total requests: ${TOTAL_REQS:-N/A}
          - request rate: ${REQ_RATE:-N/A}
          - error rate: ${ERROR_RATE:-0%}

          **response time:**
          - average: ${AVG_DURATION:-N/A}ms
          - p90: ${P90_DURATION:-N/A}ms
          - p95: ${P95_DURATION:-N/A}ms

          ### cluster info
          - cluster type: kind (multi-node)
          - nodes: 1 control-plane + 2 workers
          - ingress: nginx
          - monitoring: prometheus deployed (metrics require cAdvisor/kubelet configuration not available in basic kind setup)

          <details>
          <summary>k6 output summary (last 100 lines)</summary>

          \`\`\`
          $(tail -100 load-test-output.txt)
          \`\`\`

          </details>
          COMMENT

          cat comment.md
          EOF

          chmod +x parse-results.sh
          ./parse-results.sh

      - name: post comment to pr
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const fs = require('fs');
            const comment = fs.readFileSync('comment.md', 'utf8');

            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });

      - name: cleanup
        if: always()
        run: |
          echo "cleaning up resources..."
          kind delete cluster || true
